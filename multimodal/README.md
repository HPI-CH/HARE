# Multimodal Activity Recognition

To run mutlimodal experiments go to ` multimodal.ipynp`.

Most important helper functions can be found in `pose_sequence_loader.py`.

The directory contains similar files to the original `ml-pipeline/src`. There are only a few changes in data types to allow for multimodal modal input.
