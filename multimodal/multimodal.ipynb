{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from utils import settings as settings\n",
    "import pandas as pd\n",
    "from evaluation.metrics import accuracy\n",
    "from evaluation.conf_matrix import create_conf_matrix\n",
    "from loader.Preprocessor import Preprocessor\n",
    "from models.RainbowModel import RainbowModel\n",
    "from models.ResNetModel import ResNetModel\n",
    "from models.ResNetModel_Multimodal import ResNetModelMultimodal\n",
    "from models.LeanderDeepConvLSTM import LeanderDeepConvLSTM\n",
    "from utils.filter_activities import filter_activities\n",
    "from utils.folder_operations import new_saved_experiment_folder\n",
    "from utils.DataConfig import Sonar22CategoriesConfig, OpportunityConfig, SonarConfig, LabPoseConfig\n",
    "from tensorflow.keras.layers import (Dense)\n",
    "from utils.Recording import Recording\n",
    "import matplotlib.pyplot as plt\n",
    "import utils.DataConfig\n",
    "from pose_sequence_loader import *\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Settings & Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading recording 0_orhan_1652085453257.csv, 1 / 51\n",
      "3\n",
      "Loading recording 1_orhan_1651673896419.csv, 2 / 51\n",
      "3\n",
      "Loading recording 2_alex_1652878074983.csv, 3 / 51\n",
      "3\n",
      "Loading recording 3_daniel_1652429334344.csv, 4 / 51\n",
      "6\n",
      "Loading recording 4_lucas_1651566794296.csv, 5 / 51\n",
      "1\n",
      "Loading recording 5_orhan_1653467107120.csv, 6 / 51\n",
      "3\n",
      "Loading recording 6_orhan_1652086187708.csv, 7 / 51\n",
      "1\n",
      "Loading recording 7_marco_1651225541980.csv, 8 / 51\n",
      "3\n",
      "Loading recording 8_felix_1651152283882.csv, 9 / 51\n",
      "5\n",
      "Loading recording 9_orhan_1653481329073.csv, 10 / 51\n",
      "8\n",
      "Loading recording 10_valentin_1652869027863.csv, 11 / 51\n",
      "3\n",
      "Loading recording 11_orhan_1651674660480.csv, 12 / 51\n",
      "6\n",
      "Loading recording 12_orhan_1653480087545.csv, 13 / 51\n",
      "3\n",
      "Loading recording 13_orhan_1651674075450.csv, 14 / 51\n",
      "10\n",
      "Loading recording 14_franz_1653471714380.csv, 15 / 51\n",
      "1\n",
      "Loading recording 15_felix_1651154555588.csv, 16 / 51\n",
      "1\n",
      "Loading recording 16_kirill_1651147138832.csv, 17 / 51\n",
      "1\n",
      "Loading recording 17_orhan_1653465446990.csv, 18 / 51\n",
      "8\n",
      "Loading recording 18_daniel_1652428200498.csv, 19 / 51\n",
      "3\n",
      "Loading recording 19_valentin_1652868344398.csv, 20 / 51\n",
      "3\n",
      "Loading recording 20_orhan_1653479496235.csv, 21 / 51\n",
      "12\n",
      "Loading recording 21_valentin_1653484242836.csv, 22 / 51\n",
      "7\n",
      "Loading recording 22_franz_1651065958950.csv, 23 / 51\n",
      "3\n",
      "Loading recording 23_valentin_1652869322733.csv, 24 / 51\n",
      "3\n",
      "Loading recording 24_valentin_1653485032057.csv, 25 / 51\n",
      "6\n",
      "Loading recording 25_orhan_1652102976810.csv, 26 / 51\n",
      "1\n",
      "Loading recording 26_franz_1653470380045.csv, 27 / 51\n",
      "0\n",
      "Loading recording 27_tobi_1651221686939.csv, 28 / 51\n",
      "7\n",
      "Loading recording 28_kirill_1651149389351.csv, 29 / 51\n",
      "8\n",
      "Loading recording 29_kirill_1651139232298.csv, 30 / 51\n",
      "3\n",
      "Loading recording 30_orhan_1653468003340.csv, 31 / 51\n",
      "3\n",
      "Loading recording 31_orhan_1652710416778.csv, 32 / 51\n",
      "3\n",
      "Loading recording 32_felix_1651152887499.csv, 33 / 51\n",
      "6\n",
      "Loading recording 33_orhan_1652085113670.csv, 34 / 51\n",
      "1\n",
      "Loading recording 34_tobi_1651223183731.csv, 35 / 51\n",
      "5\n",
      "Loading recording 35_franz_1653468941680.csv, 36 / 51\n",
      "1\n",
      "Loading recording 36_lucas_1651565920786.csv, 37 / 51\n",
      "3\n",
      "Loading recording 37_felix_1652708794017.csv, 38 / 51\n",
      "3\n",
      "Loading recording 38_lucas_1651567699911.csv, 39 / 51\n",
      "1\n",
      "Loading recording 39_daniel_1652431073226.csv, 40 / 51\n",
      "12\n",
      "Loading recording 40_orhan_1653479275869.csv, 41 / 51\n",
      "12\n",
      "Loading recording 41_kirill_1651149014709.csv, 42 / 51\n",
      "8\n",
      "Loading recording 42_orhan_1651674149525.csv, 43 / 51\n",
      "10\n",
      "Loading recording 43_daniel_1652432054525.csv, 44 / 51\n",
      "12\n",
      "Loading recording 44_orhan_1653466299712.csv, 45 / 51\n",
      "1\n",
      "Loading recording 46_valentin_1653483997299.csv, 46 / 51\n",
      "5\n",
      "Loading recording 47_kirill_1651140012109.csv, 47 / 51\n",
      "3\n",
      "Loading recording 48_felix_1651153453225.csv, 48 / 51\n",
      "3\n",
      "Loading recording 49_orhan_1653477482139.csv, 49 / 51\n",
      "8\n",
      "Loading recording 50_orhan_1653463600238.csv, 50 / 51\n",
      "1\n",
      "Loading recording 51_orhan_1652101854919.csv, 51 / 51\n",
      "1\n",
      "Loaded 51 recordings from /dhc/groups/bp2021ba1/data/lab_data_filtered_without_null\n"
     ]
    }
   ],
   "source": [
    "data_config = LabPoseConfig(dataset_path='/dhc/groups/bp2021ba1/data/lab_data_filtered_without_null')#OpportunityConfig(dataset_path='/dhc/groups/bp2021ba1/data/opportunity-dataset')\n",
    "#data_config = SonarConfig(dataset_path='/dhc/groups/bp2021ba1/data/lab_data')#OpportunityConfig(dataset_path='/dhc/groups/bp2021ba1/data/opportunity-dataset')\n",
    "settings.init(data_config)\n",
    "random.seed(1678978086101)\n",
    "\n",
    "k_fold_splits = 5\n",
    "numEpochs = 10\n",
    "window_size = 600\n",
    "\n",
    "# LOAD DATA\n",
    "recordings = settings.DATA_CONFIG.load_dataset()#limit=3)\n",
    "recordings = Preprocessor().our_preprocess(recordings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append Pose Estimation Sequences to Recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording 1652429334344: Metadata has less than 2 Activities. Returning empty pose frame (!)\n",
      "Pose Frame added to Recording 4/51  \n",
      "Pose Frame added to Recording 2/51  \n",
      "Pose Frame added to Recording 7/51  \n",
      "Pose Frame added to Recording 9/51  \n",
      "Pose Frame added to Recording 11/51  \n",
      "Recording 1651674660480: Activity TimeStamps of Frame & Metadata significantly shifted. Returning empty pose frame (!)\n",
      "Pose Frame added to Recording 12/51  \n",
      "Recording 1651674075450: Metadata has less than 2 Activities. Returning empty pose frame (!)\n",
      "Pose Frame added to Recording 14/51  \n",
      "Pose Frame added to Recording 5/51  \n",
      "Pose Frame added to Recording 10/51  \n",
      "Pose Frame added to Recording 6/51  \n",
      "Pose Frame added to Recording 1/51  \n",
      "Recording 1653480087545: Activity TimeStamps of Frame & Metadata significantly shifted. Returning empty pose frame (!)\n",
      "Pose Frame added to Recording 13/51  \n",
      "Pose Frame added to Recording 3/51  \n",
      "Pose Frame added to Recording 21/51  \n",
      "Recording 1652428200498: Activity TimeStamps of Frame & Metadata significantly shifted. Returning empty pose frame (!)\n",
      "Pose Frame added to Recording 19/51  \n",
      "Pose Frame added to Recording 16/51  \n",
      "Pose Frame added to Recording 18/51  \n",
      "Pose Frame added to Recording 20/51  \n",
      "Pose Frame added to Recording 23/51  \n",
      "Pose Frame added to Recording 17/51  \n",
      "Pose Frame added to Recording 22/51  \n",
      "Recording 1651149389351: Metadata has less than 2 Activities. Returning empty pose frame (!)\n",
      "Pose Frame added to Recording 29/51  \n",
      "Recording 1653485032057: Activity TimeStamps of Frame & Metadata significantly shifted. Returning empty pose frame (!)\n",
      "Pose Frame added to Recording 25/51  \n",
      "Pose Frame added to Recording 8/51  \n",
      "Pose Frame added to Recording 24/51  \n",
      "Pose Frame added to Recording 15/51  \n",
      "Recording 1651152887499: Activity TimeStamps of Frame & Metadata significantly shifted. Returning empty pose frame (!)\n",
      "Pose Frame added to Recording 33/51  \n",
      "Pose Frame added to Recording 30/51  \n",
      "Pose Frame added to Recording 34/51  \n",
      "Pose Frame added to Recording 31/51  \n",
      "Pose Frame added to Recording 26/51  \n",
      "Pose Frame added to Recording 27/51  \n",
      "Pose Frame added to Recording 38/51  \n",
      "Recording 1653479275869: Metadata has less than 2 Activities. Returning empty pose frame (!)\n",
      "Pose Frame added to Recording 41/51  \n",
      "Recording 1651149014709: Metadata has less than 2 Activities. Returning empty pose frame (!)\n",
      "Pose Frame added to Recording 42/51  \n",
      "Pose Frame added to Recording 28/51  \n",
      "Pose Frame added to Recording 32/51  \n",
      "Pose Frame added to Recording 37/51  \n",
      "Pose Frame added to Recording 35/51  \n",
      "Pose Frame added to Recording 43/51  \n",
      "Pose Frame added to Recording 39/51  \n",
      "Pose Frame added to Recording 36/51  \n",
      "Pose Frame added to Recording 46/51  \n",
      "Pose Frame added to Recording 40/51  \n",
      "Pose Frame added to Recording 45/51  \n",
      "Pose Frame added to Recording 47/51  \n",
      "Pose Frame added to Recording 44/51  \n",
      "Pose Frame added to Recording 51/51  \n",
      "Pose Frame added to Recording 48/51  \n",
      "Pose Frame added to Recording 49/51  \n",
      "Pose Frame added to Recording 50/51  \n",
      "Filtered out 10 Recordings (!)\n",
      "==> APPENDING POSE FRAMES DONE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def process_recording(recording_with_index):\n",
    "    i = recording_with_index[0]\n",
    "    recording = recording_with_index[1]\n",
    "    pose_frame = get_poseframe(recording, \"/dhc/groups/bp2021ba1/data/lab_data\")\n",
    "    \n",
    "    print(f\"Pose Frame added to Recording {i+1}/{len(recordings)}  \")\n",
    "    return pose_frame\n",
    "\n",
    "def append_pose_frames(recordings, useMultiprocessing = True):\n",
    "    if useMultiprocessing:\n",
    "        pool = Pool()\n",
    "        pose_frames = pool.map(process_recording, list(enumerate(recordings)), 1)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    else:\n",
    "        pose_frames = []\n",
    "        for i, k in list(enumerate(recordings)):\n",
    "            pose_frames.append(process_recording((i,k)))\n",
    "\n",
    "    for i, pose_frame in enumerate(pose_frames):\n",
    "        recordings[i].pose_frame = pose_frame\n",
    "\n",
    "append_pose_frames(recordings)\n",
    "\n",
    "initialLength = len(recordings)\n",
    "recordings = list(filter(\n",
    "    lambda recording: not recording.pose_frame.empty, \n",
    "    recordings\n",
    "))\n",
    "print(f\"Filtered out {initialLength - len(recordings)} Recordings (!)\")\n",
    "\n",
    "print(\"==> APPENDING POSE FRAMES DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper for Training & Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG TRAINING\n",
    "n_sensor_features = recordings[0].sensor_frame.shape[1]\n",
    "n_pose_features = recordings[0].pose_frame.shape[1]\n",
    "print(f\"Sensor features: {n_sensor_features},  Pose features: {n_pose_features}\")\n",
    "n_outputs = settings.DATA_CONFIG.n_activities()\n",
    "\n",
    "# Create Folder, save model export and evaluations there\n",
    "experiment_folder_path = new_saved_experiment_folder(\n",
    "    \"multiModal_alex\"\n",
    ")\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "def evaluate(y_test_pred: np.ndarray, y_test_true: np.ndarray, confusionMatrixFileName=None, confusionMatrixTitle=\"\") -> tuple[float, float,float, np.ndarray]:\n",
    "    acc = accuracy(y_test_pred, y_test_true)\n",
    "    if confusionMatrixFileName:\n",
    "        create_conf_matrix(\n",
    "            experiment_folder_path, y_test_pred, y_test_true, \n",
    "            file_name = confusionMatrixFileName, title=confusionMatrixTitle+\", acc:\"+str(int(acc*10000)/100)+\"%\"\n",
    "            # label_mapping = {value: key for key, value in data_config.category_labels.items()}\n",
    "    ) \n",
    "    f1_macro = f1_score(np.argmax(y_test_true, axis=1), np.argmax(y_test_pred, axis=1), average=\"macro\")   \n",
    "    f1_weighted = f1_score(np.argmax(y_test_true, axis=1), np.argmax(y_test_pred, axis=1), average=\"weighted\")    \n",
    "    return acc, f1_macro, f1_weighted, y_test_true\n",
    "\n",
    "def save_prediction(y_test_pred: np.ndarray, y_test_true: np.ndarray, acc, f1_macro, f1_weighted, file_name: str, mode: str):\n",
    "    prefix = f\"{mode}, WS {window_size},\"\n",
    "    experiment_folder_root =  os.path.join(*experiment_folder_path.split(\"/\")[:-1])  \n",
    "    experiment_folder_end = experiment_folder_path.split(\"/\")[-1]\n",
    "    experiment_folder = os.path.join(experiment_folder_root, prefix + experiment_folder_end)\n",
    "    with open(os.path.join(experiment_folder_path , f\"{file_name}.json\"), \"w+\") as file:\n",
    "        json_dict = {\n",
    "            'Predicted Labels': y_test_pred,\n",
    "            'Actual Lables': y_test_true,\n",
    "            'Accuracy': acc,\n",
    "            'F1 Macro': f1_macro,\n",
    "            'F1 Weighted':f1_weighted\n",
    "        }\n",
    "        \n",
    "        json.dump(json_dict, file, cls=NumpyEncoder)\n",
    "\n",
    "\n",
    "def instanciateModel(use_sensor_frame = True, use_pose_frame = False) -> ResNetModelMultimodal:\n",
    "    n_features = 0\n",
    "    n_features += n_sensor_features if (use_sensor_frame) else 0\n",
    "    n_features += n_pose_features if (use_pose_frame) else 0\n",
    "\n",
    "    #return ResNetModelMultimodal(\n",
    "    return LeanderDeepConvLSTM(\n",
    "        n_epochs=numEpochs,\n",
    "        window_size=window_size,\n",
    "        n_features=n_features,\n",
    "        n_outputs=n_outputs,\n",
    "        learning_rate=0.001,\n",
    "        batch_size=64,\n",
    "        use_sensor_frame=use_sensor_frame,\n",
    "        use_pose_frame=use_pose_frame,\n",
    "        verbose = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-Recording-Out K-Fold Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def leave_recording_out_run():\n",
    "    print(\"############################### LEAVE RECORDING OUT ##########################\")\n",
    "    print(\"##############################################################################\")\n",
    "    # TRAIN AND PREDICT\n",
    "    multiModals = [(True, False), (True, True), (False, True)]\n",
    "    for modality_index, (use_sensor_frame, use_pose_frame) in enumerate(multiModals):\n",
    "        print(f\"\\n\\n==== Sensor Features: {use_sensor_frame}   Pose Features: {use_pose_frame} ====\")\n",
    "        model = instanciateModel(use_sensor_frame=use_sensor_frame, use_pose_frame=use_pose_frame)\n",
    "        model.n_epochs = numEpochs\n",
    "        model.model.save_weights(\"ckpt\")\n",
    "\n",
    "        confusion_y_test_pred = None\n",
    "        confusion_y_test_actual = None\n",
    "        avg_acc = avg_f1_macro = avg_f1_weighted = divider = 0\n",
    "        k_fold = KFold(n_splits=k_fold_splits, random_state=42, shuffle=True)\n",
    "        for k_fold_index, (train_indices, test_indices) in enumerate(k_fold.split(recordings)):\n",
    "            model.model.load_weights(\"ckpt\")\n",
    "            \n",
    "            recordingsTrain = [recordings[ind] for ind in train_indices.astype(int)]\n",
    "            recordingsTest = [recordings[ind] for ind in test_indices.astype(int)]\n",
    "\n",
    "            x_train, y_train = model.windowize_convert(recordingsTrain)\n",
    "            model.fit(x_train=x_train, y_train=y_train)\n",
    "\n",
    "            x_test, y_test_actual = model.windowize_convert(recordingsTest)\n",
    "            y_test_pred = model.predict(x_test)\n",
    "\n",
    "            confusion_y_test_pred = y_test_pred if confusion_y_test_pred is None else np.append(confusion_y_test_pred, y_test_pred, axis=0)\n",
    "            confusion_y_test_actual = y_test_actual if confusion_y_test_actual is None else np.append(confusion_y_test_actual, y_test_actual, axis=0)\n",
    "\n",
    "            acc, f1_macro, f1_weighted, _ = evaluate(\n",
    "                y_test_pred, \n",
    "                y_test_actual\n",
    "            )\n",
    "\n",
    "            weight = len(confusion_y_test_actual)\n",
    "            avg_acc += acc * weight\n",
    "            avg_f1_macro += f1_macro * weight\n",
    "            avg_f1_weighted += f1_weighted * weight\n",
    "            divider += weight\n",
    "\n",
    "            print(f\"=> K-Fold {k_fold_index+1}/{k_fold_splits}: acc: {acc}  f1 macro: {f1_macro}  f1 weighted: {f1_weighted}\\n\")\n",
    "\n",
    "        avg_acc = avg_acc / divider\n",
    "        avg_f1_macro = avg_f1_macro / divider\n",
    "        avg_f1_weighted = avg_f1_weighted / divider\n",
    "\n",
    "        save_prediction(\n",
    "                confusion_y_test_pred, confusion_y_test_actual, \n",
    "                avg_acc, avg_f1_macro, avg_f1_weighted,\n",
    "                f\"Data {'SENSOR' if use_sensor_frame else 'x'} - {'POSE' if use_pose_frame else 'x'}\",\n",
    "                mode = \"Rec\"\n",
    "            )\n",
    "        _, _, _, _ = evaluate(\n",
    "                confusion_y_test_pred, confusion_y_test_actual, \n",
    "                confusionMatrixFileName=f\"Confusion {'SENSOR' if use_sensor_frame else 'x'} - {'POSE' if use_pose_frame else 'x'}\"\n",
    "            )\n",
    "\n",
    "        print(f\"\\n\\n==== Results ====\")\n",
    "        print(f\"Accuracy: {avg_acc}\")\n",
    "        print(f\"F1 Macro: {avg_f1_macro}\")\n",
    "        print(f\"F1 Weighted: {avg_f1_weighted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-Window-Out K-Fold Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_window_out_run():\n",
    "    print(\"############################### LEAVE WINDOW OUT ##########################\")\n",
    "    print(\"##############################################################################\")\n",
    "    # TRAIN AND PREDICT\n",
    "    multiModals = [(True, False), (True, True), (False, True)]\n",
    "    for modality_index, (use_sensor_frame, use_pose_frame) in enumerate(multiModals):\n",
    "        print(f\"\\n\\n==== Sensor Features: {use_sensor_frame}   Pose Features: {use_pose_frame} ====\")\n",
    "        model = instanciateModel(use_sensor_frame=use_sensor_frame, use_pose_frame=use_pose_frame)\n",
    "        model.n_epochs = numEpochs\n",
    "        model.model.save_weights(\"ckpt\")\n",
    "\n",
    "        windows = model.windowize(recordings)\n",
    "\n",
    "        confusion_y_test_pred = None\n",
    "        confusion_y_test_actual = None\n",
    "        avg_acc = avg_f1_macro = avg_f1_weighted = divider = 0\n",
    "        k_fold = KFold(n_splits=k_fold_splits, random_state=42, shuffle=True)\n",
    "        for k_fold_index, (train_indices, test_indices) in enumerate(k_fold.split(windows)):\n",
    "            model.model.load_weights(\"ckpt\")\n",
    "            \n",
    "            windows_train = [windows[ind] for ind in train_indices.astype(int)]\n",
    "            windows_test = [windows[ind] for ind in test_indices.astype(int)]\n",
    "\n",
    "            x_train, y_train = model.convert(windows_train)\n",
    "            model.fit(x_train=x_train, y_train=y_train)\n",
    "\n",
    "            x_test, y_test_actual = model.convert(windows_test)\n",
    "            y_test_pred = model.predict(x_test)\n",
    "\n",
    "            confusion_y_test_pred = y_test_pred if confusion_y_test_pred is None else np.append(confusion_y_test_pred, y_test_pred, axis=0)\n",
    "            confusion_y_test_actual = y_test_actual if confusion_y_test_actual is None else np.append(confusion_y_test_actual, y_test_actual, axis=0)\n",
    "\n",
    "            acc, f1_macro, f1_weighted, _ = evaluate(\n",
    "                y_test_pred, \n",
    "                y_test_actual\n",
    "            )\n",
    "\n",
    "            weight = len(confusion_y_test_actual)\n",
    "            avg_acc += acc * weight\n",
    "            avg_f1_macro += f1_macro * weight\n",
    "            avg_f1_weighted += f1_weighted * weight\n",
    "            divider += weight\n",
    "\n",
    "            print(f\"=> K-Fold {k_fold_index+1}/{k_fold_splits}: acc: {acc}  f1 macro: {f1_macro}  f1 weighted: {f1_weighted}\\n\")\n",
    "\n",
    "        avg_acc = avg_acc / divider\n",
    "        avg_f1_macro = avg_f1_macro / divider\n",
    "        avg_f1_weighted = avg_f1_weighted / divider\n",
    "\n",
    "        save_prediction(\n",
    "                confusion_y_test_pred, confusion_y_test_actual, \n",
    "                avg_acc, avg_f1_macro, avg_f1_weighted,\n",
    "                f\"Data {'SENSOR' if use_sensor_frame else 'x'} - {'POSE' if use_pose_frame else 'x'}\",\n",
    "                mode = \"Win\"\n",
    "            )\n",
    "        _, _, _, _ = evaluate(\n",
    "                confusion_y_test_pred, confusion_y_test_actual, \n",
    "                confusionMatrixFileName=f\"Confusion {'SENSOR' if use_sensor_frame else 'x'} - {'POSE' if use_pose_frame else 'x'}\"\n",
    "            )\n",
    "\n",
    "        print(f\"\\n\\n==== Results ====\")\n",
    "        print(f\"Accuracy: {avg_acc}\")\n",
    "        print(f\"F1 Macro: {avg_f1_macro}\")\n",
    "        print(f\"F1 Weighted: {avg_f1_weighted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-Subject-Out Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_subject_out_run():\n",
    "    print(\"############################### LEAVE SUBJECT OUT ##########################\")\n",
    "    print(\"#############################################################################\")\n",
    "\n",
    "    subjects = set([recording.subject for recording in recordings])\n",
    "    # TRAIN AND PREDICT\n",
    "    multiModals = [(True, False), (True, True), (False, True)]\n",
    "    for modality_index, (use_sensor_frame, use_pose_frame) in enumerate(multiModals):\n",
    "        print(f\"\\n\\n==== Sensor Features: {use_sensor_frame}   Pose Features: {use_pose_frame} ====\")\n",
    "        model = instanciateModel(use_sensor_frame=use_sensor_frame, use_pose_frame=use_pose_frame)\n",
    "        model.n_epochs = numEpochs\n",
    "        model.model.save_weights(\"ckpt\")\n",
    "\n",
    "        confusion_y_test_pred = None\n",
    "        confusion_y_test_actual = None\n",
    "        avg_acc = avg_f1_macro = avg_f1_weighted = divider = 0\n",
    "        for subjectIndex, leaveOutSubject in enumerate(subjects):\n",
    "            model.model.load_weights(\"ckpt\")\n",
    "\n",
    "            recordings_train = [recording for recording in recordings if recording.subject != leaveOutSubject]\n",
    "            recordings_test = [recording for recording in recordings if recording.subject == leaveOutSubject]\n",
    "\n",
    "            x_train, y_train = model.windowize_convert(recordings_train)\n",
    "            model.fit(x_train=x_train, y_train=y_train)\n",
    "\n",
    "            x_test, y_test_actual = model.windowize_convert(recordings_test)\n",
    "            y_test_pred = model.predict(x_test)\n",
    "\n",
    "            confusion_y_test_pred = y_test_pred if confusion_y_test_pred is None else np.append(confusion_y_test_pred, y_test_pred, axis=0)\n",
    "            confusion_y_test_actual = y_test_actual if confusion_y_test_actual is None else np.append(confusion_y_test_actual, y_test_actual, axis=0)\n",
    "\n",
    "            acc, f1_macro, f1_weighted, _ = evaluate(\n",
    "                y_test_pred, \n",
    "                y_test_actual\n",
    "            )\n",
    "\n",
    "            weight = len(confusion_y_test_actual)\n",
    "            avg_acc += acc * weight\n",
    "            avg_f1_macro += f1_macro * weight\n",
    "            avg_f1_weighted += f1_weighted * weight\n",
    "            divider += weight\n",
    "\n",
    "            print(f\"=> Subject {subjectIndex+1}/{len(subjects)}: acc: {acc}  f1 macro: {f1_macro}  f1 weighted: {f1_weighted}\\n\")\n",
    "\n",
    "        avg_acc = avg_acc / divider\n",
    "        avg_f1_macro = avg_f1_macro / divider\n",
    "        avg_f1_weighted = avg_f1_weighted / divider\n",
    "\n",
    "        save_prediction(\n",
    "                confusion_y_test_pred, confusion_y_test_actual, \n",
    "                avg_acc, avg_f1_macro, avg_f1_weighted,\n",
    "                f\"Data {'SENSOR' if use_sensor_frame else 'x'} - {'POSE' if use_pose_frame else 'x'}\",\n",
    "                mode = \"Subj\"\n",
    "            )\n",
    "        _, _, _, _ = evaluate(\n",
    "                confusion_y_test_pred, confusion_y_test_actual, \n",
    "                confusionMatrixFileName=f\"Confusion {'SENSOR' if use_sensor_frame else 'x'} - {'POSE' if use_pose_frame else 'x'}\"\n",
    "            )\n",
    "\n",
    "        print(f\"\\n\\n==== Results ====\")\n",
    "        print(f\"Accuracy: {avg_acc}\")\n",
    "        print(f\"F1 Macro: {avg_f1_macro}\")\n",
    "        print(f\"F1 Weighted: {avg_f1_weighted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Exeriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_recording_out_run()\n",
    "leave_window_out_run()\n",
    "leave_subject_out_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings = list(filter(\n",
    "    lambda recording: not recording.pose_frame.empty, \n",
    "    recordings\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "33997 33997 33997 33997\n",
      "8788 8788 8788 8788\n",
      "36641 36641 36641 36641\n",
      "35555 35555 35555 35555\n",
      "36521 36521 36521 36521\n",
      "16939 16939 16939 16939\n",
      "74915 74915 74915 74915\n",
      "23015 23015 23015 23015\n",
      "23883 23883 23883 23883\n",
      "7483 7483 7483 7483\n",
      "58993 58993 58993 58993\n",
      "21139 21139 21139 21139\n",
      "35706 35706 35706 35706\n",
      "25052 25052 25052 25052\n",
      "25356 25356 25356 25356\n",
      "2752 2752 2752 2752\n",
      "25852 25852 25852 25852\n",
      "18937 18937 18937 18937\n",
      "31664 31664 31664 31664\n",
      "41591 41591 41591 41591\n",
      "51041 51041 51041 51041\n",
      "49105 49105 49105 49105\n",
      "21424 21424 21424 21424\n",
      "26687 26687 26687 26687\n",
      "50123 50123 50123 50123\n",
      "11742 11742 11742 11742\n",
      "46128 46128 46128 46128\n",
      "51715 51715 51715 51715\n",
      "34589 34589 34589 34589\n",
      "16358 16358 16358 16358\n",
      "39763 39763 39763 39763\n",
      "38520 38520 38520 38520\n",
      "10788 10788 10788 10788\n",
      "48943 48943 48943 48943\n",
      "36946 36946 36946 36946\n",
      "10037 10037 10037 10037\n",
      "31142 31142 31142 31142\n",
      "43414 43414 43414 43414\n",
      "45219 45219 45219 45219\n",
      "57752 57752 57752 57752\n",
      "29118 29118 29118 29118\n"
     ]
    }
   ],
   "source": [
    "from numpy import size\n",
    "\n",
    "print(len(recordings))\n",
    "\n",
    "for r in recordings:\n",
    "    print(len(r.time_frame),len(r.activities),len(r.sensor_frame),len(r.pose_frame))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1089694856.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [18]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for recording in recordings[]:\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for recording in recordings:\n",
    "    complete_frame = pd.concat([recording.time_frame, recording.activities], axis=1)\n",
    "    complete_frame = pd.concat([complete_frame, recording.sensor_frame], axis=1)\n",
    "    complete_frame = pd.concat([complete_frame, recording.pose_frame], axis=1)\n",
    "\n",
    "    filename = f\"{recording.recording_index} - {recording.subject} - {recording.recording_folder}\"  \n",
    "    complete_frame.to_csv(f\"/dhc/groups/bp2021ba1/alex/UnicornML/src/skeleton_imu_csv_data/{filename}.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2171cf73acafe344dfae972adc9cb578812877998169c8a7c19a1c4d43d1a332"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('alex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
